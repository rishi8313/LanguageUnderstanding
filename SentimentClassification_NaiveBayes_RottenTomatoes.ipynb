{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sentiment Analysis of Rotten Tomatoes Reviews using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Some imports to make code compatible with Python 2 as well as 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import nltk, the Natural Language Processing Toolkit\n",
    "\n",
    "This is one of the most popular packages for natural language processing on text data. It has APIs to access a large corpus of documents and other lexical resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "3.2.1\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Extract the review text and corresponding sentiment label from the review files\n",
    "\n",
    "The dataset is available for download from this site: http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "\n",
    "Search for \"sentence polarity dataset v1.0 (includes sentence polarity dataset README v1.0: 5331 positive and 5331 negative processed sentences / snippets. Introduced in Pang/Lee ACL 2005. Released July 2005.\"\n",
    "\n",
    "This is the dataset to download, unzip and untar.\n",
    "\n",
    "**Store the files with positive and negative reviews (rt-polarity.pos and rt-polarity.neg) in the same directory as this code**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_reviews(path, positive=True):\n",
    "    label = 1 if positive else 0\n",
    "\n",
    "    reviews = []\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        review_text = f.readlines()\n",
    "        \n",
    "    for text in review_text:\n",
    "        # Return a tuple of the review text and a label for whether it \n",
    "        # is a positive or negative review\n",
    "        reviews.append((text, label))\n",
    "\n",
    "    return reviews           \n",
    "\n",
    "def extract_reviews():\n",
    "    positive_reviews = get_reviews(\"rt-polarity.pos\", positive=True)\n",
    "    negative_reviews = get_reviews(\"rt-polarity.neg\", positive=False)\n",
    "\n",
    "    return positive_reviews, negative_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "positive_reviews, negative_reviews = extract_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \\n',\n",
       "  1),\n",
       " ('the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth . \\n',\n",
       "  1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = 5000\n",
    "TOTAL_DATA = 6000\n",
    "\n",
    "train_reviews = positive_reviews[:TRAIN_DATA] + negative_reviews[:TRAIN_DATA]\n",
    "\n",
    "test_positive_reviews = positive_reviews[TRAIN_DATA:TOTAL_DATA]\n",
    "test_negative_reviews = negative_reviews[TRAIN_DATA:TOTAL_DATA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of all the unque words in the dataset, the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_vocabulary(train_reviews):\n",
    "    words_set = set()\n",
    "    \n",
    "    for review in train_reviews:\n",
    "        words_set.update(review[0].split())\n",
    "    \n",
    "    return list(words_set)\n",
    "\n",
    "vocabulary = get_vocabulary(train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20704"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unimaginative', 'writings', 'bad-boy', 'ryoko', 'foul']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Represent the words in the review as a feature vector\n",
    "\n",
    "* *review_text* The review in text form\n",
    "\n",
    "Each review is represented as a dictionary where keys are all words in the vocabulary. The values associated with each key is True if the word is present in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_features(review_text):\n",
    "    # Split the review into words, and create a set of the words\n",
    "    review_words = set(review_text.split())\n",
    "    \n",
    "    features = {}\n",
    "    for word in vocabulary:\n",
    "        features[word] = (word in review_words)\n",
    "        \n",
    "    return features    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map feature vector to labels\n",
    "\n",
    "* *extract_features* Function to extract the features in feature vector form\n",
    "* *train_reviews* Training dataset, a list of tuples of the form (review_text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_features = nltk.classify.apply_features(extract_features, train_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the classifier on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trained_classifier = nltk.NaiveBayesClassifier.train(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sentiment_calculator(review_text):\n",
    "    features = extract_features(review_text)\n",
    "    return trained_classifier.classify(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_calculator(\"What an amazing movie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_calculator(\"What a terrible movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify and measure the accuracy of the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def classify_test_reviews(test_positive_reviews, test_negative_reviews, sentiment_calculator):\n",
    "    positive_results = [sentiment_calculator(review[0]) for review in test_positive_reviews]\n",
    "    negative_results = [sentiment_calculator(review[0]) for review in test_negative_reviews]\n",
    "    \n",
    "    true_positives = sum(x > 0 for x in positive_results)\n",
    "    true_negatives = sum(x == 0 for x in negative_results)\n",
    "    \n",
    "    percent_true_positive = float(true_positives) / len(positive_results)\n",
    "    percent_true_negative = float(true_negatives) / len(negative_results)\n",
    "\n",
    "    total_accurate = true_positives + true_negatives\n",
    "    total = len(positive_results) + len(negative_results)\n",
    "\n",
    "    print(\"Accuracy on positive reviews = \" +\"%.2f\" % (percent_true_positive * 100) + \"%\")\n",
    "    print(\"Accurance on negative reviews = \" +\"%.2f\" % (percent_true_negative * 100) + \"%\")\n",
    "    print(\"Overall accuracy = \" + \"%.2f\" % (total_accurate * 100/ total) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on positive reviews = 78.25%\n",
      "Accurance on negative reviews = 80.66%\n",
      "Overall accuracy = 79.46%\n"
     ]
    }
   ],
   "source": [
    "classify_test_reviews(test_positive_reviews, test_negative_reviews, sentiment_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
